{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from CustomGymEnv import CustomGymEnv\n",
    "import torch\n",
    "from grid2op.Parameters import Parameters\n",
    "from examples.ppo_stable_baselines.B_train_agent import CustomReward\n",
    "from lightsim2grid import LightSimBackend\n",
    "from grid2op.Chronics import MultifolderWithCache\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020-2022 RTE (https://www.rte-france.com)\n",
    "# See AUTHORS.txt\n",
    "# This Source Code Form is subject to the terms of the Mozilla Public License, version 2.0.\n",
    "# If a copy of the Mozilla Public License, version 2.0 was not distributed with this file,\n",
    "# you can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "# SPDX-License-Identifier: MPL-2.0\n",
    "# This file is part of L2RPN Baselines, L2RPN Baselines a repository to host baselines for l2rpn competitions.\n",
    "\n",
    "import warnings\n",
    "import copy\n",
    "import os\n",
    "import grid2op\n",
    "import json\n",
    "\n",
    "from grid2op.gym_compat import BoxGymActSpace, BoxGymObsSpace, GymEnv\n",
    "\n",
    "from l2rpn_baselines.PPO_SB3.utils import SB3Agent\n",
    "\n",
    "try:\n",
    "    from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.ppo import MlpPolicy\n",
    "    _CAN_USE_STABLE_BASELINE = True\n",
    "except ImportError:\n",
    "    _CAN_USE_STABLE_BASELINE = False\n",
    "    class MlpPolicy(object):\n",
    "        \"\"\"\n",
    "        Do not use, this class is a template when stable baselines3 is not installed.\n",
    "        \n",
    "        It represents `from stable_baselines3.ppo import MlpPolicy`\n",
    "        \"\"\"\n",
    "    \n",
    "from l2rpn_baselines.PPO_SB3.utils import (default_obs_attr_to_keep, \n",
    "                                           default_act_attr_to_keep,\n",
    "                                           remove_non_usable_attr,\n",
    "                                           save_used_attribute)\n",
    "\n",
    "\n",
    "def get_agent(env,\n",
    "          name=\"PPO_SB3\",\n",
    "          iterations=1,\n",
    "          save_path=None,\n",
    "          load_path=None,\n",
    "          net_arch=None,\n",
    "          logs_dir=None,\n",
    "          learning_rate=3e-4,\n",
    "          save_every_xxx_steps=None,\n",
    "          model_policy=MlpPolicy,\n",
    "          obs_attr_to_keep=copy.deepcopy(default_obs_attr_to_keep),\n",
    "          obs_space_kwargs=None,\n",
    "          act_attr_to_keep=copy.deepcopy(default_act_attr_to_keep),\n",
    "          act_space_kwargs=None,\n",
    "          policy_kwargs=None,\n",
    "          normalize_obs=False,\n",
    "          normalize_act=False,\n",
    "          gymenv_class=GymEnv,\n",
    "          gymenv_kwargs=None,\n",
    "          verbose=True,\n",
    "          seed=None,  # TODO\n",
    "          eval_env=None,  # TODO\n",
    "          **kwargs):\n",
    "    \n",
    "    if not _CAN_USE_STABLE_BASELINE:\n",
    "        raise ImportError(\"Cannot use this function as stable baselines3 is not installed\")\n",
    "    \n",
    "    # keep only usable attributes (if default is used)\n",
    "    act_attr_to_keep = remove_non_usable_attr(env, act_attr_to_keep)\n",
    "    \n",
    "    # save the attributes kept\n",
    "    if save_path is not None:\n",
    "        my_path = os.path.join(save_path, name)\n",
    "    save_used_attribute(save_path, name, obs_attr_to_keep, act_attr_to_keep)\n",
    "\n",
    "    # define the gym environment from the grid2op env\n",
    "    if gymenv_kwargs is None:\n",
    "        gymenv_kwargs = {}\n",
    "    env_gym = gymenv_class(env, **gymenv_kwargs)\n",
    "    env_gym.observation_space.close()\n",
    "    if obs_space_kwargs is None:\n",
    "        obs_space_kwargs = {}\n",
    "    env_gym.observation_space = BoxGymObsSpace(env.observation_space,\n",
    "                                               attr_to_keep=obs_attr_to_keep,\n",
    "                                               **obs_space_kwargs)\n",
    "    env_gym.action_space.close()\n",
    "    if act_space_kwargs is None:\n",
    "        act_space_kwargs = {}\n",
    "    env_gym.action_space = BoxGymActSpace(env.action_space,\n",
    "                                          attr_to_keep=act_attr_to_keep,\n",
    "                                          **act_space_kwargs)\n",
    "\n",
    "    if normalize_act:\n",
    "        if save_path is not None:\n",
    "            with open(os.path.join(my_path, \".normalize_act\"), encoding=\"utf-8\", \n",
    "                      mode=\"w\") as f:\n",
    "                f.write(\"I have encoded the action space !\\n DO NOT MODIFY !\")\n",
    "        for attr_nm in act_attr_to_keep:\n",
    "            if ((\"multiply\" in act_space_kwargs and attr_nm in act_space_kwargs[\"multiply\"]) or \n",
    "                (\"add\" in act_space_kwargs and attr_nm in act_space_kwargs[\"add\"]) \n",
    "               ):\n",
    "                # attribute is scaled elsewhere\n",
    "                continue\n",
    "            env_gym.action_space.normalize_attr(attr_nm)\n",
    "\n",
    "    if normalize_obs:\n",
    "        if save_path is not None:\n",
    "            with open(os.path.join(my_path, \".normalize_obs\"), encoding=\"utf-8\", \n",
    "                      mode=\"w\") as f:\n",
    "                f.write(\"I have encoded the observation space !\\n DO NOT MODIFY !\")\n",
    "        for attr_nm in obs_attr_to_keep:\n",
    "            if ((\"divide\" in obs_space_kwargs and attr_nm in obs_space_kwargs[\"divide\"]) or \n",
    "                (\"subtract\" in obs_space_kwargs and attr_nm in obs_space_kwargs[\"subtract\"]) \n",
    "               ):\n",
    "                # attribute is scaled elsewhere\n",
    "                continue\n",
    "            env_gym.observation_space.normalize_attr(attr_nm)\n",
    "    \n",
    "    # Save a checkpoint every \"save_every_xxx_steps\" steps\n",
    "    checkpoint_callback = None\n",
    "    if save_every_xxx_steps is not None:\n",
    "        if save_path is None:\n",
    "            warnings.warn(\"save_every_xxx_steps is set, but no path are \"\n",
    "                          \"set to save the model (save_path is None). No model \"\n",
    "                          \"will be saved.\")\n",
    "        else:\n",
    "            checkpoint_callback = CheckpointCallback(save_freq=save_every_xxx_steps,\n",
    "                                                     save_path=my_path,\n",
    "                                                     name_prefix=name)\n",
    "\n",
    "    # define the policy\n",
    "    if load_path is None:\n",
    "        if policy_kwargs is None:\n",
    "            policy_kwargs = {}\n",
    "        if net_arch is not None:\n",
    "            policy_kwargs[\"net_arch\"] = net_arch\n",
    "        if logs_dir is not None:\n",
    "            if not os.path.exists(logs_dir):\n",
    "                os.mkdir(logs_dir)\n",
    "            this_logs_dir = os.path.join(logs_dir, name)\n",
    "        else:\n",
    "            this_logs_dir = None\n",
    "                \n",
    "        nn_kwargs = {\n",
    "            \"policy\": model_policy,\n",
    "            \"env\": env_gym,\n",
    "            \"verbose\": verbose,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"tensorboard_log\": this_logs_dir,\n",
    "            \"policy_kwargs\": policy_kwargs,\n",
    "            **kwargs\n",
    "        }\n",
    "        agent = SB3Agent(env.action_space,\n",
    "                         env_gym.action_space,\n",
    "                         env_gym.observation_space,\n",
    "                         nn_kwargs=nn_kwargs,\n",
    "        )\n",
    "    else:        \n",
    "        agent = SB3Agent(env.action_space,\n",
    "                         env_gym.action_space,\n",
    "                         env_gym.observation_space,\n",
    "                         nn_path=os.path.join(load_path, name)\n",
    "        )\n",
    "    return agent, env_gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"l2rpn_wcci_2022_dev\"\n",
    "env_name_train = '_'.join([ENV_NAME, \"train\"])\n",
    "save_path = \"./agent\"\n",
    "name = \"CustomGymEnv\"\n",
    "gymenv_class = CustomGymEnv\n",
    "\n",
    "train_args = {}\n",
    "\n",
    "# Utility parameters PPO\n",
    "train_args[\"logs_dir\"] = \"./logs\"\n",
    "train_args[\"save_path\"] = save_path\n",
    "train_args[\"name\"] = name\n",
    "train_args[\"verbose\"] = 1\n",
    "train_args[\"gymenv_class\"] = gymenv_class\n",
    "train_args[\"device\"] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_args[\"obs_attr_to_keep\"] = [\"month\", \"day_of_week\", \"hour_of_day\", \"minute_of_hour\",\n",
    "                                  \"gen_p\", \"load_p\", \n",
    "                                  \"p_or\", \"rho\", \"timestep_overflow\", \"line_status\",\n",
    "                                  # dispatch part of the observation\n",
    "                                  \"actual_dispatch\", \"target_dispatch\",\n",
    "                                  # storage part of the observation\n",
    "                                  \"storage_charge\", \"storage_power\",\n",
    "                                  # curtailment part of the observation\n",
    "                                  \"curtailment\", \"curtailment_limit\",  \"gen_p_before_curtail\",\n",
    "                                  ]\n",
    "train_args[\"act_attr_to_keep\"] = [\"set_storage\", \"curtail\"]\n",
    "train_args[\"iterations\"] = 700_000\n",
    "train_args[\"learning_rate\"] = 1e-4\n",
    "train_args[\"net_arch\"] = [300, 300, 300]\n",
    "train_args[\"gamma\"] = 0.999\n",
    "train_args[\"gymenv_kwargs\"] = {\"safe_max_rho\": 0.1}\n",
    "train_args[\"normalize_act\"] = True\n",
    "train_args[\"normalize_obs\"] = True\n",
    "\n",
    "train_args[\"save_every_xxx_steps\"] = min(train_args[\"iterations\"] // 10, 100_000)\n",
    "\n",
    "train_args[\"n_steps\"] = 16\n",
    "train_args[\"batch_size\"] = 16\n",
    "\n",
    "p = Parameters()\n",
    "p.LIMIT_INFEASIBLE_CURTAILMENT_STORAGE_ACTION = True\n",
    "\n",
    "env = grid2op.make(ENV_NAME,\n",
    "                   reward_class=CustomReward,\n",
    "                   backend=LightSimBackend(),\n",
    "                   chronics_class=MultifolderWithCache,\n",
    "                   param=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "with open(\"../preprocess_obs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  obs_space_kwargs = json.load(f)\n",
    "with open(\"../preprocess_act.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  act_space_kwargs = json.load(f)\n",
    "\n",
    "agent, gym_env = get_agent(env,\n",
    "          obs_space_kwargs=obs_space_kwargs,\n",
    "          act_space_kwargs=act_space_kwargs,\n",
    "          **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"expert_data.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050.0\n",
      "This action will:\n",
      "\t - NOT change anything to the injections\n",
      "\t - Modify the generators with redispatching in the following way:\n",
      "\t \t - Redispatch \"gen_7_2\" of 0.31 MW\n",
      "\t \t - Redispatch \"gen_11_6\" of 0.62 MW\n",
      "\t \t - Redispatch \"gen_14_8\" of 0.02 MW\n",
      "\t \t - Redispatch \"gen_17_10\" of -0.06 MW\n",
      "\t \t - Redispatch \"gen_25_13\" of 0.02 MW\n",
      "\t \t - Redispatch \"gen_41_19\" of 0.08 MW\n",
      "\t \t - Redispatch \"gen_53_25\" of 0.32 MW\n",
      "\t \t - Redispatch \"gen_59_31\" of -0.14 MW\n",
      "\t \t - Redispatch \"gen_60_32\" of -0.17 MW\n",
      "\t \t - Redispatch \"gen_64_35\" of -0.01 MW\n",
      "\t \t - Redispatch \"gen_68_37\" of 0.02 MW\n",
      "\t \t - Redispatch \"gen_69_38\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_76_41\" of 0.00 MW\n",
      "\t \t - Redispatch \"gen_76_42\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_82_45\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_91_51\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_99_53\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_103_55\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_110_58\" of 0.01 MW\n",
      "\t \t - Redispatch \"gen_112_60\" of -0.10 MW\n",
      "\t - Modify the storage units in the following way:\n",
      "\t \t - Ask unit \"storage_22_0\" to absorb 1.52 MW (setpoint: 1.52 MW)\n",
      "\t \t - Ask unit \"storage_41_1\" to produce 7.75 MW (setpoint: -7.75 MW)\n",
      "\t \t - Ask unit \"storage_44_2\" to produce 9.65 MW (setpoint: -9.65 MW)\n",
      "\t \t - Ask unit \"storage_58_3\" to produce 9.57 MW (setpoint: -9.57 MW)\n",
      "\t \t - Ask unit \"storage_76_4\" to produce 0.89 MW (setpoint: -0.89 MW)\n",
      "\t \t - Ask unit \"storage_95_5\" to produce 0.75 MW (setpoint: -0.75 MW)\n",
      "\t \t - Ask unit \"storage_112_6\" to absorb 10.20 MW (setpoint: 10.20 MW)\n",
      "\t - Perform the following curtailment:\n",
      "\t \t - Limit unit \"gen_18_11\" to 0.0% of its Pmax (setpoint: 0.000)\n",
      "\t \t - Limit unit \"gen_24_12\" to 17.2% of its Pmax (setpoint: 0.172)\n",
      "\t \t - Limit unit \"gen_26_14\" to 14.6% of its Pmax (setpoint: 0.146)\n",
      "\t \t - Limit unit \"gen_26_15\" to 18.9% of its Pmax (setpoint: 0.189)\n",
      "\t \t - Limit unit \"gen_61_33\" to 3.5% of its Pmax (setpoint: 0.035)\n",
      "\t \t - Limit unit \"gen_61_34\" to 0.1% of its Pmax (setpoint: 0.001)\n",
      "\t - NOT force any line status\n",
      "\t - NOT switch any line status\n",
      "\t - NOT switch anything in the topology\n",
      "\t - NOT force any particular bus configuration\n"
     ]
    }
   ],
   "source": [
    "act = data.get(\"expert_actions\")[0]\n",
    "obs = data.get(\"expert_observations\")[0]\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = gym_env.action_space.dict_properties[\"curtail\"][0]\n",
    "high = gym_env.action_space.dict_properties[\"curtail\"][1]\n",
    "\n",
    "curtail = act.curtail.copy()[env.gen_renewable]\n",
    "curtail = curtail / (high - low) + low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = gym_env.action_space.dict_properties[\"set_storage\"][0]\n",
    "high = gym_env.action_space.dict_properties[\"set_storage\"][1]\n",
    "\n",
    "storage = act.storage_p.copy() / act_space_kwargs[\"multiply\"][\"set_storage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This action will:\n",
      "\t - NOT change anything to the injections\n",
      "\t - NOT perform any redispatching action\n",
      "\t - Modify the storage units in the following way:\n",
      "\t \t - Ask unit \"storage_22_0\" to absorb 1.52 MW (setpoint: 1.52 MW)\n",
      "\t \t - Ask unit \"storage_41_1\" to produce 7.75 MW (setpoint: -7.75 MW)\n",
      "\t \t - Ask unit \"storage_44_2\" to produce 9.65 MW (setpoint: -9.65 MW)\n",
      "\t \t - Ask unit \"storage_58_3\" to produce 9.57 MW (setpoint: -9.57 MW)\n",
      "\t \t - Ask unit \"storage_76_4\" to produce 0.89 MW (setpoint: -0.89 MW)\n",
      "\t \t - Ask unit \"storage_95_5\" to produce 0.75 MW (setpoint: -0.75 MW)\n",
      "\t \t - Ask unit \"storage_112_6\" to absorb 10.20 MW (setpoint: 10.20 MW)\n",
      "\t - Perform the following curtailment:\n",
      "\t \t - Limit unit \"gen_18_11\" to 0.0% of its Pmax (setpoint: 0.000)\n",
      "\t \t - Limit unit \"gen_24_12\" to 17.2% of its Pmax (setpoint: 0.172)\n",
      "\t \t - Limit unit \"gen_26_14\" to 14.6% of its Pmax (setpoint: 0.146)\n",
      "\t \t - Limit unit \"gen_26_15\" to 18.9% of its Pmax (setpoint: 0.189)\n",
      "\t \t - Limit unit \"gen_61_33\" to 3.5% of its Pmax (setpoint: 0.035)\n",
      "\t \t - Limit unit \"gen_61_34\" to 0.1% of its Pmax (setpoint: 0.001)\n",
      "\t - NOT force any line status\n",
      "\t - NOT switch any line status\n",
      "\t - NOT switch anything in the topology\n",
      "\t - NOT force any particular bus configuration\n"
     ]
    }
   ],
   "source": [
    "gym_action = np.concatenate((curtail, storage))\n",
    "print(gym_env.action_space.from_gym(gym_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_rho: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.50000197, ..., 0.5       , 0.5       ,\n",
       "       0.5       ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2op_obs = env.reset()\n",
    "g2op_obs.from_vect(obs)\n",
    "print(f\"max_rho: {g2op_obs.rho.max():.4f}\")\n",
    "gym_env.observation_space.to_gym(g2op_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential(\n",
       "      (0): Linear(in_features=1225, out_features=300, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=300, out_features=49, bias=True)\n",
       "  (value_net): Linear(in_features=300, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.nn_model.policy"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25edc466125f4cec8abda921974b846defd6af997a9da267187bfa098e2439de"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('L2RPN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
